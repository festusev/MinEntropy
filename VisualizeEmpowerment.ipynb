{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dece4e-dbf9-4f8b-87cf-82f78a85e1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/evanellis/miniconda3/envs/minent/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Loaded MediumLevelActionManager from /nas/ucb/evanellis/MinEntropy/overcooked_ai/src/overcooked_ai_py/data/planners/coordination_ring_am.pkl\n"
     ]
    }
   ],
   "source": [
    "from Empowerment import Empowerment\n",
    "from bpd.envs.overcooked import (\n",
    "    OvercookedCallbacks,\n",
    "    OvercookedMultiAgent,\n",
    "    get_littered_start_state_fn,\n",
    ")\n",
    "from overcooked_ai_py.mdp.actions import Action\n",
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "empowerment_model = Empowerment(in_channels=26, device=device)\n",
    "\n",
    "num_training_iters = 3000\n",
    "train_batch_size = 10000\n",
    "\n",
    "layout_name = \"coordination_ring\"\n",
    "rew_shaping_params = {\n",
    "    \"PLACEMENT_IN_POT_REW\": 3,\n",
    "    \"DISH_PICKUP_REWARD\": 3,\n",
    "    \"SOUP_PICKUP_REWARD\": 5,\n",
    "    \"DISH_DISP_DISTANCE_REW\": 0,\n",
    "    \"POT_DISTANCE_REW\": 0,\n",
    "    \"SOUP_DISTANCE_REW\": 0,\n",
    "}\n",
    "compute_smirl = True\n",
    "horizon = 400\n",
    "num_littered_objects = 0\n",
    "start_state_fn = get_littered_start_state_fn(\n",
    "        num_littered_objects, OvercookedGridworld.from_layout_name(layout_name)\n",
    "    )\n",
    "\n",
    "# Reward shaping\n",
    "use_phi = False  # Whether dense reward should come from potential function or not\n",
    "# Constant by which shaped rewards are multiplied by when calculating total reward\n",
    "reward_shaping_factor = 1.0\n",
    "# Linearly anneal the reward shaping factor such that it reaches zero after this\n",
    "# number of timesteps\n",
    "reward_shaping_horizon = num_training_iters * train_batch_size // 2\n",
    "# Whether the agents should both get all dense rewards.\n",
    "share_dense_reward = False\n",
    "dispense_reward = 0\n",
    "no_regular_reward = False\n",
    "action_rewards = [0] * Action.NUM_ACTIONS\n",
    "\n",
    "policy_ids = [\"smirl_e_0\", \"ppo_0\"]\n",
    "\n",
    "env_config = {\n",
    "    # To be passed into OvercookedGridWorld constructor\n",
    "    \"mdp_params\": {\n",
    "        \"layout_name\": layout_name,\n",
    "        \"rew_shaping_params\": rew_shaping_params,\n",
    "        \"empowerment_model\": empowerment_model,\n",
    "        \"smirl\": compute_smirl\n",
    "    },\n",
    "    # To be passed into OvercookedEnv constructor\n",
    "    \"env_params\": {\n",
    "        \"horizon\": horizon,\n",
    "        \"start_state_fn\": start_state_fn,\n",
    "        \"num_mdp\": 1,\n",
    "    },\n",
    "    # To be passed into OvercookedMultiAgent constructor\n",
    "    \"multi_agent_params\": {\n",
    "        \"reward_shaping_factor\": reward_shaping_factor,\n",
    "        \"reward_shaping_horizon\": reward_shaping_horizon,\n",
    "        \"use_phi\": use_phi,\n",
    "        \"share_dense_reward\": share_dense_reward,\n",
    "        \"bc_schedule\": OvercookedMultiAgent.self_play_bc_schedule,\n",
    "        \"extra_rew_shaping\": {\n",
    "            \"onion_dispense\": dispense_reward,\n",
    "            \"dish_dispense\": dispense_reward,\n",
    "        },\n",
    "        \"no_regular_reward\": no_regular_reward,\n",
    "        \"action_rewards\": action_rewards,\n",
    "        \"agents\": policy_ids\n",
    "    },\n",
    "}\n",
    "\n",
    "overcooked_env_config = env_config\n",
    "env = OvercookedMultiAgent.from_config(overcooked_env_config)\n",
    "\n",
    "def rollout(n):\n",
    "    def update(lst, val):\n",
    "        lst[\"smirl_e_0\"].append(val[\"smirl_e_0\"])\n",
    "        lst[\"ppo_0\"].append(val[\"ppo_0\"])\n",
    "\n",
    "    all_obs = []\n",
    "    all_actions = []\n",
    "    all_rewards = []\n",
    "    all_infos = []\n",
    "    for i in range(n):\n",
    "        for lst in [all_obs, all_actions, all_rewards, all_infos]:\n",
    "            lst.append({\"smirl_e_0\": [], \"ppo_0\": []})\n",
    "\n",
    "        obs = env.reset()\n",
    "\n",
    "        all_obs[-1][\"smirl_e_0\"].append(obs[\"smirl_e_0\"])\n",
    "        all_obs[-1][\"ppo_0\"].append(obs[\"ppo_0\"])\n",
    "\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = {\"ppo_0\": env.action_space.sample(), \"smirl_e_0\": env.action_space.sample()}\n",
    "            obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "            update(all_obs[-1], obs)\n",
    "            update(all_actions[-1], action)\n",
    "            update(all_rewards[-1], rewards)\n",
    "            update(all_infos[-1], infos)\n",
    "\n",
    "            done = dones[\"__all__\"]\n",
    "    return all_obs, all_actions, all_rewards, all_infos\n",
    "\n",
    "def get_multiagent_batch():\n",
    "    all_obs, all_actions, all_rewards, all_infos = rollout(1)\n",
    "\n",
    "    batch = []\n",
    "    for policy_id in policy_ids:\n",
    "        batch.append({\"obs\": np.array(all_obs[0][policy_id])[:-1], \"new_obs\": np.array(all_obs[0][policy_id][1:]),\n",
    "                 \"actions\": np.array(all_actions[0][policy_id])})\n",
    "\n",
    "    return batch\n",
    "\n",
    "validation = get_multiagent_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b5c424-2c8d-4cb7-8941-a3883c3b210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[0][\"obs\"][0][..., :26].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e9ace-4958-468b-af13-5e300c972d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
